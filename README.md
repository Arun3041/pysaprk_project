# pysaprk_project
 implemented within Docker, utilizing Amazon S3 for storage, PostgreSQL for database management


# prerequisite
 before you begin, make sure you completed these steps.
  - Install docker 
  - build pyspark Image 
  - pull PostgreSQL Image

# Overview

 - Dumping CSV into Amazon S3
   
- Reading from S3 and Creating a Pyspark Table
  
- Storing Data in PostgreSQL
  
- Reading from postgeSQL and converting Data to Parquet Format
  
- Storing Parquet Files in S3
